---
title: "Gathering and preparation of data"
author: "Anne Hobert"
date: "2/26/2020"
output:
  pdf_document:
    fig_caption: yes
    keep_md: yes
  github_document: default
    fig_caption: yes
  html_document:
    fig_caption: yes
    keep_md: yes
urlcolor: blue
---

```{r, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  fig.width = 6,
  fig.asp = 0.618,
  out.width = "70%",
  fig.align = "center",
  dpi = 300
)


# Call libraries

library(tidyverse)
library(RJDBC)
library(DBI)
library(dbplyr)
library(viridis)
library(bigrquery)

# Store personal authentication credentials as kb_user01 and kb_password01 in .Renviron file.
# Open DB connection

drv <-RJDBC::JDBC("oracle.jdbc.OracleDriver", classPath= "jdbc_driver/ojdbc8.jar")
con_kb <- DBI::dbConnect(drv, "jdbc:oracle:thin:@//biblio-p-db01:1521/bibliodb01.fiz.karlsruhe", Sys.getenv("kb_user01"), Sys.getenv("kb_password01"))

# connection to bigquery
con_bq <- dbConnect(
  bigrquery::bigquery(),
  project = "api-project-764811344545",
  dataset = "oadoi_full"
)

```

We want to investigate the journal publication output of the German research system, focussing on 5+2 pillars, namely universities, non-university research institutes, and federal as well as state (LÃ¤nder) institutions. To this end, we first gathered the following publications indexed in the WoS instance of the German Competence Center for bibliometrics, which are associated with an institution belonging to one of the seven considered sectors:

- Web of Science core collections SCI, SSCI and AHCI
- document types `Article` and `Review`
- publication years 2010 until 2018

The query used to collect all these publications is stored as file [create_pubs_german_pillars.sql](create_pubs_german_pillars.sql). We load the data into a tibble.

```{r}
pubs_wos <- DBI::dbGetQuery(con_kb, read_file("gather_pubs_german_pillars.sql"))
pubs_wos <- pubs_wos %>% 
  mutate(DOI = tolower(DOI))
```

We then extract DOI information from this publication list in order to obtain the open access status from our instance of the most recent Unpaywall data dump from November 2019.

```{r}
dois_wos <- pubs_wos %>% 
  select(DOI) %>%
  filter(!is.na(DOI))%>% 
#  mutate(DOI = tolower(DOI)) %>% 
  distinct()
```

We write this doi list as a table into the BigQuery environment we use for OA information from Unpaywall (see [our blog post on Unpaywall evidence](https://subugoe.github.io/scholcomm_analytics/posts/unpaywall_evidence/) for details on how we use BigQuery). The schema has to be specified. We do it by predefining an (empty table) in BigQuery with fitting schema and calling this from BigQuery before writing dois.

```{r}
dois_wos_bq <- bigrquery::bq_table(project = "api-project-764811344545",
                            dataset = "oadoi_full",
                            table = "oa_german_inst_dois")

dois_wos_bq_schema <- dois_wos_bq %>% 
  bigrquery::bq_table_fields()

dois_wos_bq %>% 
  bigrquery::bq_table_delete()

dois_wos_bq %>%
  bigrquery::bq_table_upload(values = dois_wos, fields = dois_wos_bq_schema)

#alternatively
#bigrquery::bq_table_upload("api-project-764811344545.oadoi_full.oa_german_inst_dois", values = dois_wos, fields = dois_wos_bq_schema)

#or using DBI 
#DBI::dbWriteTable(con_bq, "oa_german_inst_dois", dois_wos, overwrite = TRUE, fields =  dois_wos_bq_schema)
```

In order to then obtain the OA information for these articles that is contained in Unpaywall, we create a corresponding table in BigQuery by running [create_oa_german_inst_upw_evidence.sql](create_oa_german_inst_upw_evidence.sql). We then load the data and match it to the publication list drawn from WoS-KB.

```{r}
upw_evidence_bq <- bigrquery::bq_table(project = "api-project-764811344545",
                            dataset = "oadoi_full",
                            table = "oa_german_inst_upw_evidence")
upw_evidence_bq %>%
  bigrquery::bq_table_delete()

#use create_*.sql to also create the table in BQ, gather_*.sql to just load the entries

#using bq_*
upw_evidence_bq_table <- bigrquery::bq_project_query("api-project-764811344545", query = read_file("create_oa_german_inst_upw_evidence.sql")) 
upw_evidence <- bq_table_download(upw_evidence_bq_table)

#alternatively with DBI:
upw_evidence <- DBI::dbGetQuery(con_bq, read_file("gather_oa_german_inst_upw_evidence.sql"))
```


